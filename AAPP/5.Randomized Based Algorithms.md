
The randomize algorithm are algorithm that will run differently depending on the result of random "coin tosses".
![[Pasted image 20230928164007.png]]
In those algorithm is likely that they work well on the average case, so they shuffle the data in someway to make it similar to the average case.
This algorithms make the worst case very unlikely, for example shuffling the data.

When analyzing randomized algorithms, several essential tools are frequently employed:

- **Indicator Variables:** These are used to simplify the analysis of complex random variables by breaking them down into individual events or outcomes. They help isolate specific events of interest. X=sum<sub>i</sub> (X<sub>i</sub>)
- **Linearity of Expectations:** This principle allows us to calculate the expected value of the sum of random variables by adding their individual expected values. It simplifies the process of calculating the overall expected performance of an algorithm. If z=x+y -> E[z]=E[x]+E[y]
- **Recurrence Relations:** These mathematical relationships are often used to describe how the performance of an algorithm or a process depends on its previous states or iterations. They are particularly useful for understanding how an algorithm's behavior evolves over time. (as we seen for standard algorithm)


# Hiring problem and Generating random permutation

## The problem
n the hiring problem, the goal is to hire the best candidate while minimizing hiring and firing costs. The headhunter sends you 'n' applicants, one at a time. You need to decide whether to hire or reject each applicant based on their quality. Once you hire an applicant, you must fire the current employee (if any) and hire the new one. The cost of hiring and firing is expensive, and the aim is to minimize the overall cost.

To analyze this problem using expected value and indicator variables:

1. **Setup:**
    
    - Define 'n' as the number of applicants.
    - Assume 'n' applicants arrive in a certain order.
2. **Random Variables and Indicator Variables:**
    
    - Define a set of indicator random variables, denoted as Xi, where i varies from 1 to n. Each Xi represents whether or not the 'i-th' applicant is hired. It takes the value 1 if hired and 0 if rejected.
3. **Expected Value of Hiring:**
    
    - The number of applicants hired, denoted as 'X,' is the sum of all the Xi values: X = Î£Xi (from i=1 to n).
4. **Expectation of Xi:**
    
    - The expectation of Xi, E[Xi], represents the probability that the 'i-th' applicant is hired. This probability depends on the quality of the applicants and the order in which they arrive.
5. **Expected Value of Total Cost:**
    
    - The total cost in terms of hiring and firing is proportional to the number of hires. Therefore, you're interested in calculating the expected value E[X], which is the expected number of hires.
6. **Calculating E[X] :**
    
    - To calculate E[X], you need to sum up the expectations of individual Xi values:
        - E[X] = E[X1 + X2 + ... + Xn]
        - By the linearity of expectations, E[X] can be expressed as the sum of individual expectations: E[X] = E[X1] + E[X2] + ... + E[Xn].
7. **Determining E[Xi] :**
    
    - The probability that the 'i-th' applicant is hired, E[Xi], depends on the order of applicants. If there are 'i' applicants who are better than the previous ones, the probability that the 'i-th' applicant is hired is 1/i.
    - This means E[Xi] = 1/i.
8. **Expected Value of Total Hires:**
    
    - So, the expected number of hires, E[X], is calculated by summing these probabilities over all 'n' applicants:
        - E[X] = 1/1 + 1/2 + 1/3 + ... + 1/n.
9. **Simplifying E[X] :**
    
    - This expression is essentially the sum of the harmonic series, which can be approximated as ln(n) + O(1). Therefore, the expected number of hires is approximately ln(n).

In summary, the expected number of hires in the hiring problem, analyzed using the concept of expected value and indicator variables, is approximately the natural logarithm of 'n.' This analysis provides insights into how the problem behaves on average across different orderings of applicants, allowing you to make informed decisions while minimizing hiring and firing costs.

If we causally sort how we send the applicants and we want to see how many times the third applicant is better than the previous we can easily see that this do not happens in the majority of the case:
![[Pasted image 20231023121015.png]]
so in the majority of the case we are in a optimal case.

This property to not fall in the worst case in the majority of the times can be found in more and less all the randomized algorithm, since they actively change the input to make the average case most likely to happens!

# Las Vegas and Monte Carlo
There are two types of randomized based algorithm:
1. Las Vegas
2. Monte Carlo

The main difference between this two category is related to the results they output: 
- Las Vegas algorithms always gives the correct solutions, the only thing that change from a run to another is the running time
- Monte Carlo may sometimes produce a incorrect solution, but we are able to bound the probability of such uncertainty
We can further divide Monte Carlo algorithms in 2 classes:
- **One-sided error**: probability that the output is zero at least for one of the possible output (yes=yes /no=maybe no maybe yes)
- **Two-sided error**: no zero probability that the output is incorrect for each of the possible output

**Which is better, Monte Carlo or Las Vegas?**
- The answer depends on the application - in some applications an incorrect solution may be catastrophic.
- A Las Vegas algorithm is by definition a Monte Carlo algorithm with error probability 0. 
- A Las Vegas algorithm is an efficient Las Vegas algorithm if on any input its expected running time is bounded by a polynomial function of the input size.
- A Monte Carlo algorithm is an efficient Monte Carlo algorithm if on any input its worst-case running time is bounded by a polynomial function of the input size.

## Search with Randomized based Algorithm
### Monte Carlo
Monte Carlo Algorithm: Finding 'a' in Array A

**Input:**
- `A`: Array of elements
- `n`: Number of elements in the array
- `k`: Number of attempts to find 'a'

**Output:**
- The probability of finding 'a' after k attempts

```python
function findingA_MC(array A, n, k)
    i = 1
    repeat
        Randomly select one element out of n elements.
        i = i + 1
    until i = k or 'a' is found
end
````
This algorithm does not guarantee success, but the runtime is fixed at O(k) because it always makes exactly `k` attempts to find 'a'.
The probability of finding a is:
p(find 'a')=1 - 1/2<sup>k</sup>
### Las Vegas

**Input:**
- `A`: Array of elements
- `n`: Number of elements in the array

**Output:**
- Success when 'a' is found

```python
function findingA_LV(array A, n)
    repeat
        Randomly select one element out of n elements.
    until 'a' is found
end
````
This Las Vegas algorithm aims to find the element 'a' in the given array `A`. It repeatedly selects an element from the array at random until it finds 'a'. The algorithm succeeds with a probability of 1 (i.e., it guarantees success). However, the running time is not fixed and may vary depending on how many attempts it takes to find 'a'. The running time is random and can be expressed as a random variable.
# Kager's min-cut algorithm
## The problem

